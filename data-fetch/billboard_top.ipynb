{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Demo Snippet of getting the correct weekly billboard date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Billboard top album sales dates are weekly and they start on Sunday, end on Saturday. The chart title always corresponds to a Saturday. For example, Top Album sales the week of 2019-09-28 which is a Saturday. This is always true for the URL corresponding to that week's top 100 albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-10-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '2019-09-19' ## Billboards data should end at week of 2019-09-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "chart_week_dates = []\n",
    "current_dt = start_dt # would be best if start date is a valid week of date, i.e. a saturday\n",
    "while(current_dt > end_dt):\n",
    "    chart_week_dates.append(str(current_dt.date()))    \n",
    "    current_dt = current_dt - timedelta(days=7)\n",
    "    # exit loop as soon as current date less than end date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-10-05', '2019-09-28', '2019-09-21']\n"
     ]
    }
   ],
   "source": [
    "print(chart_week_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now generate the correct list of dates for our dataset\n",
    "The end date will be the publication date of the first pitchfork review: '1999-01-05' which can be verified with reviews.pub_date.min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-10-05' # Week before final's week of module 1\n",
    "end_date = '1999-01-05' \n",
    "\n",
    "start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "chart_week_dates = []\n",
    "current_dt = start_dt # would be best if start date is a valid week of date, i.e. a saturday\n",
    "while(current_dt > end_dt):\n",
    "    chart_week_dates.append(str(current_dt.date()))    \n",
    "    current_dt = current_dt - timedelta(days=7)\n",
    "    # exit loop as soon as current date less than end date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now time to fetch the billboard charts data\n",
    "We will store everything in a dictonary first with the {key:value} pair being {(artist,album_name):peak_position). The key is a tuple of (artist,album_name), the value is the peak position in the charts of the album. When updating the dictionary, we will check if the currently stored peak position is less than this week's peak position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import billboard\n",
    "import requests\n",
    "import backoff\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a while to run because it's scraping the website, also we will sleep every 1 to 5 seconds to avoid 429 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, requests.exceptions.RequestException)\n",
    "def get_chart(url): # Use exponential backoff when there's a 429 request error\n",
    "    print('Requesting... '+url)\n",
    "    chart = billboard.ChartData(url)\n",
    "    print('FINISH')\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_urls = ['top-album-sales/'+date for date in chart_week_dates]\n",
    "charts=[]\n",
    "while len(api_urls) != 0:\n",
    "    url = api_urls.pop(0)\n",
    "    chart = get_chart(url)\n",
    "    charts.append(chart)\n",
    "    sleep_sec = round(random.random(),2)*10 % 5\n",
    "    time.sleep(sleep_sec)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chart.pkl','wb') as fp:\n",
    "    pickle.dump(charts,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_ranks = defaultdict(lambda: 666) # default ranking is 666 which is lower than 100 (lowest possible rank)\n",
    "\n",
    "for entry in chart:\n",
    "    artist_name = entry.artist\n",
    "    album_name = entry.title\n",
    "    peak_chart_ranking = entry.peakPos\n",
    "    key = (artist_name,album_name)\n",
    "    if album_ranks[key] > peak_chart_ranking: # If stored rank is lower than this week's peak, we replace the stored rank with the new higher ranking\n",
    "        album_ranks[key] = peak_chart_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_chart_ranks = pd.DataFrame(columns=['artist','title','peak_chart_ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_chart_ranks = pd.DataFrame(columns=['artist','title','peak_chart_ranking'])\n",
    "counter = 0\n",
    "for key,peak_chart_ranking in album_ranks.items():\n",
    "    artist_name,album_name = key\n",
    "    new_row = [artist_name.lower().strip(),album_name.lower().strip(),peak_chart_ranking]\n",
    "    billboard_chart_ranks.loc[counter] = new_row\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_chart_ranks.to_csv('chart_rankings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
